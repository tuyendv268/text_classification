{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"XLM.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"869907e0be9f479dbc6e9de99f4c7085":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2c56cf867d5d4c05b7bb6880bacb8c77","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_53be39d36c77491dbee72ff3ca5d08b3","IPY_MODEL_f67aa2536eb748de987931ae819d9944","IPY_MODEL_9e00eb279bcf4bcc8abc1ef3af2684d9"]}},"2c56cf867d5d4c05b7bb6880bacb8c77":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"53be39d36c77491dbee72ff3ca5d08b3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8ffaccfc31484b90864aa9757555f280","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_83f61504f3404ae0b70d5b49bab139b3"}},"f67aa2536eb748de987931ae819d9944":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_899bb93f039f4bd9be59874adcb60a32","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":2952532,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2952532,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7475109f86534a9c8384bbac3d4d2824"}},"9e00eb279bcf4bcc8abc1ef3af2684d9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3830fa45d7234296b7a99b2804e9a165","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2.82M/2.82M [00:00&lt;00:00, 23.8MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_910c3f71785246548be4f536a18bae48"}},"8ffaccfc31484b90864aa9757555f280":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"83f61504f3404ae0b70d5b49bab139b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"899bb93f039f4bd9be59874adcb60a32":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"7475109f86534a9c8384bbac3d4d2824":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3830fa45d7234296b7a99b2804e9a165":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"910c3f71785246548be4f536a18bae48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4008a6f55a17427f9634a842bae3b5f9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_19d89a283d084c1daa1f2839d31fe176","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5e014ea2c7944d2896f3c4160e3ec19c","IPY_MODEL_ea4e013e52d246f0acfa643ef3860b8d","IPY_MODEL_ee01b23ea7c2443ca75168c0cb12f7e5"]}},"19d89a283d084c1daa1f2839d31fe176":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5e014ea2c7944d2896f3c4160e3ec19c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4043cb974e2d417eb96a0e9220d0d014","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_810a9022cef440e68ffacd3b96fb723f"}},"ea4e013e52d246f0acfa643ef3860b8d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f9e6be82fd754cccbfa64872147fe164","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1434601,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1434601,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a3447ce6b265477d85e7ca96fdfda86e"}},"ee01b23ea7c2443ca75168c0cb12f7e5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3fc9c7c06ea84721b50c531a26d88ea1","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.37M/1.37M [00:00&lt;00:00, 18.6MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4a27099f94754823ad9a76339d3e6083"}},"4043cb974e2d417eb96a0e9220d0d014":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"810a9022cef440e68ffacd3b96fb723f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f9e6be82fd754cccbfa64872147fe164":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a3447ce6b265477d85e7ca96fdfda86e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3fc9c7c06ea84721b50c531a26d88ea1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4a27099f94754823ad9a76339d3e6083":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fe0631fae90c44af9b7f280c11c40d39":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f047cac2dac04b04b1ef70ae23efd853","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_481845ed2eba4dfe8732a2e77b8adfcf","IPY_MODEL_3ba128a06d264707b59cdb3f9d1f7c63","IPY_MODEL_34b02e8a71ae4c1885e13dbf566c658f"]}},"f047cac2dac04b04b1ef70ae23efd853":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"481845ed2eba4dfe8732a2e77b8adfcf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_401eb434f2c441089aec10dfef7237b3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0371f080f19f44469e80cdf16a49d227"}},"3ba128a06d264707b59cdb3f9d1f7c63":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_add0fa62ff694e0dbd89f0655bcba6c6","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":401,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":401,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ac27d14179824ea3a9f09703cd013beb"}},"34b02e8a71ae4c1885e13dbf566c658f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_580ad8be66ce49928114977430a8a1e9","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 401/401 [00:00&lt;00:00, 14.3kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e3ab38fc680a46f2809f075022cfbc72"}},"401eb434f2c441089aec10dfef7237b3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0371f080f19f44469e80cdf16a49d227":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"add0fa62ff694e0dbd89f0655bcba6c6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ac27d14179824ea3a9f09703cd013beb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"580ad8be66ce49928114977430a8a1e9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e3ab38fc680a46f2809f075022cfbc72":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"daa2286c122b49439e67a91ef7cf1b1e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a29daa24249a4f92881da7adf78db68f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b3a591a243284e839a17ce6d1a1b1b39","IPY_MODEL_9eb3bbc21e7d42528dd99cdc9894787a","IPY_MODEL_53be77cc5fa64dab8d5a8692dfda020b"]}},"a29daa24249a4f92881da7adf78db68f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b3a591a243284e839a17ce6d1a1b1b39":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e2ad5a87b78a459e9a408b2378f97618","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_eebba8e1b80341c783fcee6331f190ed"}},"9eb3bbc21e7d42528dd99cdc9894787a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_229ea5ed11e944daa74f9c555b6362ac","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1399,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1399,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_515391030c834730bd9205718a178c1f"}},"53be77cc5fa64dab8d5a8692dfda020b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_36d8715b3a2f443dadaaa91c5062e8cd","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.37k/1.37k [00:00&lt;00:00, 41.5kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8c389e26df35401caa46718270b65e40"}},"e2ad5a87b78a459e9a408b2378f97618":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"eebba8e1b80341c783fcee6331f190ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"229ea5ed11e944daa74f9c555b6362ac":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"515391030c834730bd9205718a178c1f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"36d8715b3a2f443dadaaa91c5062e8cd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8c389e26df35401caa46718270b65e40":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"caf4791df6c6499b882360eb7aff1f7d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4ef9540d9053456e9f0db2fc069b8a20","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9e42896b5efe4fa5b4bf1237b20bcc32","IPY_MODEL_99edb7127b5b4d32955f04b2a3638961","IPY_MODEL_aa00e42d87f746cdb84a373ec616a2d3"]}},"4ef9540d9053456e9f0db2fc069b8a20":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9e42896b5efe4fa5b4bf1237b20bcc32":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_67e66a195b2e4a998ff471d42d422258","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cc9230ef7cfa459c830bc2d728e8a5d8"}},"99edb7127b5b4d32955f04b2a3638961":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_afc50eeafb874ab5aec5fc3f8c910b23","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":692734777,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":692734777,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_67f9fc483002467c8fde8e8114fc67e7"}},"aa00e42d87f746cdb84a373ec616a2d3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e9f3a42631ab4669b40472616e7e5d6e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 661M/661M [00:23&lt;00:00, 31.5MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b51a0a3e9338491ca608c96c745d9d37"}},"67e66a195b2e4a998ff471d42d422258":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"cc9230ef7cfa459c830bc2d728e8a5d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"afc50eeafb874ab5aec5fc3f8c910b23":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"67f9fc483002467c8fde8e8114fc67e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e9f3a42631ab4669b40472616e7e5d6e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b51a0a3e9338491ca608c96c745d9d37":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yjulYVfXX_9x","executionInfo":{"status":"ok","timestamp":1642320091819,"user_tz":-420,"elapsed":7097,"user":{"displayName":"Tuyển Dương","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgL_7fwmi-6wsXMnaiF7SDMv2ievunYgF-1pGos=s64","userId":"04424011376780897176"}},"outputId":"c54160fd-cadb-42ed-dbb0-b5deff430bb8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.15.0-py3-none-any.whl (3.4 MB)\n","\u001b[K     |████████████████████████████████| 3.4 MB 25.9 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 6.8 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 65.7 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 75.1 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n","Collecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 65.5 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.10.3 transformers-4.15.0\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E0BNJGgRXe7i"},"outputs":[],"source":["from transformers import XLMTokenizer, XLMModel, XLMForSequenceClassification\n","import torch\n","import pandas as pd\n","import numpy as np\n","import torch.nn as nn\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","from sklearn.metrics import roc_auc_score, accuracy_score\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import json\n","import tqdm"]},{"cell_type":"code","source":["cuda = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"z3iObjkRgW_Z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Data Loading"],"metadata":{"id":"4266FrqwaiDQ"}},{"cell_type":"code","source":["with open(\"/content/drive/MyDrive/Fine-Tune-Bert/TextClassification/Data/datasetVNTC.json\") as json_file:\n","  data = json.load(json_file)"],"metadata":{"id":"sdXUUD78ahuU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data.keys()\n","data['target_names']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iDUF-G3ia6xJ","executionInfo":{"status":"ok","timestamp":1642320103078,"user_tz":-420,"elapsed":14,"user":{"displayName":"Tuyển Dương","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgL_7fwmi-6wsXMnaiF7SDMv2ievunYgF-1pGos=s64","userId":"04424011376780897176"}},"outputId":"6a597d4e-ecc0-4d14-d356-a7dd64721218"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['chính trị xã hội',\n"," 'khoa học',\n"," 'kinh doanh',\n"," 'pháp luật',\n"," 'sức khỏe',\n"," 'thế giới',\n"," 'thể thao',\n"," 'vi tính',\n"," 'văn hóa',\n"," 'đời sống']"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["print(len(data['data']))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jTHW-o8YbIKW","executionInfo":{"status":"ok","timestamp":1642320103080,"user_tz":-420,"elapsed":14,"user":{"displayName":"Tuyển Dương","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgL_7fwmi-6wsXMnaiF7SDMv2ievunYgF-1pGos=s64","userId":"04424011376780897176"}},"outputId":"707ce9f3-b783-4f10-e479-1a5be76d5553"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["33759\n"]}]},{"cell_type":"code","source":["class TextDataset(Dataset):\n","  def __init__(self, X, y, tokenizer, max_length):\n","    super(TextDataset, self).__init__()\n","    self.tokenizer = tokenizer\n","    self.max_length = max_length\n","    self.X = X\n","    self.y = y\n","  def __len__(self):\n","    return len(self.y)\n","  def __getitem__(self, index):\n","    text = self.X[index]\n","    inputs = self.tokenizer.encode_plus(\n","        text,\n","        None,\n","        pad_to_max_length = True,\n","        add_special_tokens = True,\n","        return_attention_mask = True,\n","        max_length = self.max_length,\n","        return_tensors = 'pt', \n","    )\n","    ids = inputs[\"input_ids\"].reshape(self.max_length)\n","    token_type_ids = inputs[\"token_type_ids\"].reshape(self.max_length)\n","    mask = inputs[\"attention_mask\"].reshape(self.max_length)\n","\n","    return{\n","        \"ids\" : ids.to(cuda),\n","        \"mask\" : mask.to(cuda),\n","        \"token_type_ids\" : token_type_ids.to(cuda),\n","        \"target\" : torch.tensor(self.y[index], dtype = torch.long, device = cuda),\n","    }"],"metadata":{"id":"6MWvTCIwbNnR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer = XLMTokenizer.from_pretrained('xlm-mlm-tlm-xnli15-1024')\n"],"metadata":{"id":"iZNFuDVNgpxF","executionInfo":{"status":"ok","timestamp":1642320104300,"user_tz":-420,"elapsed":1230,"user":{"displayName":"Tuyển Dương","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgL_7fwmi-6wsXMnaiF7SDMv2ievunYgF-1pGos=s64","userId":"04424011376780897176"}},"colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["869907e0be9f479dbc6e9de99f4c7085","2c56cf867d5d4c05b7bb6880bacb8c77","53be39d36c77491dbee72ff3ca5d08b3","f67aa2536eb748de987931ae819d9944","9e00eb279bcf4bcc8abc1ef3af2684d9","8ffaccfc31484b90864aa9757555f280","83f61504f3404ae0b70d5b49bab139b3","899bb93f039f4bd9be59874adcb60a32","7475109f86534a9c8384bbac3d4d2824","3830fa45d7234296b7a99b2804e9a165","910c3f71785246548be4f536a18bae48","4008a6f55a17427f9634a842bae3b5f9","19d89a283d084c1daa1f2839d31fe176","5e014ea2c7944d2896f3c4160e3ec19c","ea4e013e52d246f0acfa643ef3860b8d","ee01b23ea7c2443ca75168c0cb12f7e5","4043cb974e2d417eb96a0e9220d0d014","810a9022cef440e68ffacd3b96fb723f","f9e6be82fd754cccbfa64872147fe164","a3447ce6b265477d85e7ca96fdfda86e","3fc9c7c06ea84721b50c531a26d88ea1","4a27099f94754823ad9a76339d3e6083","fe0631fae90c44af9b7f280c11c40d39","f047cac2dac04b04b1ef70ae23efd853","481845ed2eba4dfe8732a2e77b8adfcf","3ba128a06d264707b59cdb3f9d1f7c63","34b02e8a71ae4c1885e13dbf566c658f","401eb434f2c441089aec10dfef7237b3","0371f080f19f44469e80cdf16a49d227","add0fa62ff694e0dbd89f0655bcba6c6","ac27d14179824ea3a9f09703cd013beb","580ad8be66ce49928114977430a8a1e9","e3ab38fc680a46f2809f075022cfbc72","daa2286c122b49439e67a91ef7cf1b1e","a29daa24249a4f92881da7adf78db68f","b3a591a243284e839a17ce6d1a1b1b39","9eb3bbc21e7d42528dd99cdc9894787a","53be77cc5fa64dab8d5a8692dfda020b","e2ad5a87b78a459e9a408b2378f97618","eebba8e1b80341c783fcee6331f190ed","229ea5ed11e944daa74f9c555b6362ac","515391030c834730bd9205718a178c1f","36d8715b3a2f443dadaaa91c5062e8cd","8c389e26df35401caa46718270b65e40"]},"outputId":"674a27ca-1ece-42f9-b219-7de2a50f42ae"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"869907e0be9f479dbc6e9de99f4c7085","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/2.82M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4008a6f55a17427f9634a842bae3b5f9","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/1.37M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fe0631fae90c44af9b7f280c11c40d39","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/401 [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"daa2286c122b49439e67a91ef7cf1b1e","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/1.37k [00:00<?, ?B/s]"]},"metadata":{}}]},{"cell_type":"code","source":["datatest = TextDataset(data['data'][30000:], data['target'][30000:],tokenizer, 256)\n","datatrain = TextDataset(data['data'][0:30000], data['target'][0:30000],tokenizer, 256)"],"metadata":{"id":"pPSMqIdYfxnG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["datatrainloader = DataLoader(dataset = datatrain, batch_size = 32)\n","datatestloader = DataLoader(dataset = datatest, batch_size = 32)"],"metadata":{"id":"CmwZYB8-f9sf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Build Model"],"metadata":{"id":"Nx3ifE5QansF"}},{"cell_type":"code","source":["xlm = XLMForSequenceClassification.from_pretrained('xlm-mlm-tlm-xnli15-1024', problem_type=\"multi_label_classification\", num_labels = 10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":156,"referenced_widgets":["caf4791df6c6499b882360eb7aff1f7d","4ef9540d9053456e9f0db2fc069b8a20","9e42896b5efe4fa5b4bf1237b20bcc32","99edb7127b5b4d32955f04b2a3638961","aa00e42d87f746cdb84a373ec616a2d3","67e66a195b2e4a998ff471d42d422258","cc9230ef7cfa459c830bc2d728e8a5d8","afc50eeafb874ab5aec5fc3f8c910b23","67f9fc483002467c8fde8e8114fc67e7","e9f3a42631ab4669b40472616e7e5d6e","b51a0a3e9338491ca608c96c745d9d37"]},"id":"t376wZhg6wTT","executionInfo":{"status":"ok","timestamp":1642320130081,"user_tz":-420,"elapsed":25790,"user":{"displayName":"Tuyển Dương","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgL_7fwmi-6wsXMnaiF7SDMv2ievunYgF-1pGos=s64","userId":"04424011376780897176"}},"outputId":"12abb8c6-6111-414d-b1b4-4582805d1b6f"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"caf4791df6c6499b882360eb7aff1f7d","version_minor":0,"version_major":2},"text/plain":["Downloading:   0%|          | 0.00/661M [00:00<?, ?B/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at xlm-mlm-tlm-xnli15-1024 were not used when initializing XLMForSequenceClassification: ['pred_layer.proj.bias', 'pred_layer.proj.weight']\n","- This IS expected if you are initializing XLMForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLMForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLMForSequenceClassification were not initialized from the model checkpoint at xlm-mlm-tlm-xnli15-1024 and are newly initialized: ['transformer.position_ids', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["model = xlm.to(cuda)\n","loss_function = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr = 1e-5)"],"metadata":{"id":"5gg9UKCAgMhG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import gc\n","gc.collect()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JAR8wE_k8LMG","executionInfo":{"status":"ok","timestamp":1642303905298,"user_tz":-420,"elapsed":319,"user":{"displayName":"Tuyen Duong Van","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtTacBQ6s-40IAkPpB9UiqHRK4GYzu8VaLeAEr9g=s64","userId":"13283457235207767479"}},"outputId":"cb5ef67b-8aaa-49d9-fd2f-7ae83a855bf6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1429"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["model.train()\n","total_train_loss = 0\n","training_loss = []\n","for epoch in range(5):\n","  loop = tqdm.tqdm(enumerate(datatrainloader), leave=False, total=len(datatrainloader))\n","  total_train_loss = 0\n","  for batch, dl in loop:\n","    ids = dl['ids']\n","    token_type_ids = dl['token_type_ids']\n","    mask = dl['mask']\n","    label = dl['target']\n","    label = torch.nn.functional.one_hot(label, 10).float().to(cuda)\n","\n","    optimizer.zero_grad()\n","\n","    output = model(ids, attention_mask=mask,labels=label)\n","\n","    loss = output[0]\n","\n","    total_train_loss = total_train_loss + loss.item()\n","\n","    loss.backward()\n","    optimizer.step()\n","    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","    \n","    loop.set_description(f'Epoch={epoch}/5')\n","    loop.set_postfix(loss=loss.item())\n","  print('Train loss:' ,total_train_loss)\n"," \n","  torch.save(model.state_dict(), '/content/drive/MyDrive/Fine-Tune-Bert/TextClassification/XLM/XLMmodel.pt')\n","  "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x_ZllbSEhfNr","outputId":"b7ab30a2-11d4-4244-9cc0-e468eb7f0866","executionInfo":{"status":"ok","timestamp":1642315850589,"user_tz":-420,"elapsed":168687,"user":{"displayName":"Tuyen Duong Van","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtTacBQ6s-40IAkPpB9UiqHRK4GYzu8VaLeAEr9g=s64","userId":"13283457235207767479"}}},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["  0%|          | 0/938 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2232: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train loss: 310.91717529296875\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":[""]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train loss: 145.6964723840356\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":[""]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train loss: 107.89401977881789\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":[""]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train loss: 108.4966600779444\n"]},{"output_type":"stream","name":"stderr","text":[""]},{"output_type":"stream","name":"stdout","text":["Train loss: 78.9078916888684\n"]}]},{"cell_type":"markdown","source":["#Assess"],"metadata":{"id":"vb7fepvkgdMo"}},{"cell_type":"code","source":["xlm.load_state_dict(torch.load('/content/drive/MyDrive/Fine-Tune-Bert/TextClassification/XLM/XLMmodel.pt'), strict=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sQhQv0X2hdIX","executionInfo":{"status":"ok","timestamp":1642320150370,"user_tz":-420,"elapsed":20294,"user":{"displayName":"Tuyển Dương","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgL_7fwmi-6wsXMnaiF7SDMv2ievunYgF-1pGos=s64","userId":"04424011376780897176"}},"outputId":"eb6d531e-db3b-4085-c28c-5b365cfb0750"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["xlm = xlm.to(cuda)"],"metadata":{"id":"Ukb6tkY7jjbd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import gc\n","gc.collect()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9Wy-qPkjrylJ","executionInfo":{"status":"ok","timestamp":1642317847147,"user_tz":-420,"elapsed":373,"user":{"displayName":"Tuyen Duong Van","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtTacBQ6s-40IAkPpB9UiqHRK4GYzu8VaLeAEr9g=s64","userId":"13283457235207767479"}},"outputId":"aaa1767c-2ac9-4cfe-bdd9-32b73e7a8ea1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["433"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["import torch\n","torch.cuda.empty_cache()"],"metadata":{"id":"p5yj9-kf6ZzT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[" evaluate(xlm, datatestloader)"],"metadata":{"id":"FrO7QBb53rso"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["evaluate(xlm, datatrainloader)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":435},"id":"ETyp723U4Ke3","executionInfo":{"status":"error","timestamp":1642317761748,"user_tz":-420,"elapsed":381,"user":{"displayName":"Tuyen Duong Van","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtTacBQ6s-40IAkPpB9UiqHRK4GYzu8VaLeAEr9g=s64","userId":"13283457235207767479"}},"outputId":"904ad3da-4264-44d5-803a-1b18dac746f2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/938 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2232: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-13d6dfb9c202>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxlm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatatrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-22-36e5972e280c>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(xlm, datatestloader)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxlm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/xlm/modeling_xlm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, langs, token_type_ids, position_ids, lengths, cache, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    830\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m         )\n\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/xlm/modeling_xlm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, langs, token_type_ids, position_ids, lengths, cache, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtoken_type_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m             \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m         \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m         \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mtensor\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/normalization.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         return F.layer_norm(\n\u001b[0;32m--> 190\u001b[0;31m             input, self.normalized_shape, self.weight, self.bias, self.eps)\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2345\u001b[0m             \u001b[0mlayer_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2346\u001b[0m         )\n\u001b[0;32m-> 2347\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 14.76 GiB total capacity; 13.42 GiB already allocated; 7.75 MiB free; 13.44 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}]},{"cell_type":"code","source":["y_true = targets_list\n","y_pred = np.argmax(predict, axis=2)\n"],"metadata":{"id":"X1Xryqi11Lxv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print([item for sublist in y_true for item in sublist])\n","print([item for sublist in y_pred for item in sublist])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UQPZ27mywZEt","executionInfo":{"status":"ok","timestamp":1642302568780,"user_tz":-420,"elapsed":364,"user":{"displayName":"Tuyen Duong Van","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtTacBQ6s-40IAkPpB9UiqHRK4GYzu8VaLeAEr9g=s64","userId":"13283457235207767479"}},"outputId":"ac7e895d-3b48-435d-decc-3f7d3342bed0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[8, 1, 9, 9, 14, 3, 5, 9, 6, 1, 4, 3, 6, 5, 11, 0, 12, 14, 2, 3, 9, 2, 7, 12, 2, 4, 1, 0, 4, 0, 1, 8, 0, 6, 4, 1, 3, 3, 8, 12, 10, 8, 7, 12, 1, 7, 7, 0, 3, 3, 12, 11, 1, 10, 0, 8, 3, 8, 11, 13, 6, 8, 2, 9, 12, 8, 5, 3, 2, 3, 7, 0, 13, 1, 0, 13, 3, 0, 2, 2, 12, 0, 4, 14, 11, 5, 10, 13, 2, 14, 4, 5, 11, 6, 14, 3, 5, 14, 3, 12, 10, 0, 0, 7, 12, 13, 7, 0, 0, 8, 5, 8, 7, 11, 14, 7, 14, 4, 2, 9, 2, 12, 3, 2, 13, 8, 8, 5, 6, 3, 5, 7, 12, 4, 3, 13, 7, 0, 12, 2, 12, 9, 8, 14, 13, 10, 7, 8, 6, 13, 13, 5, 0, 11, 7, 4, 11, 14, 6, 9, 6, 11, 8, 3, 3, 9, 8, 0, 12, 11, 9, 12, 9, 1, 8, 10, 6, 4, 3, 7, 3, 9, 4, 8, 6, 10, 14, 9, 0, 3, 0, 12, 8, 5, 2, 10, 7, 12, 2, 12, 2, 8, 3, 5, 14, 9, 13, 7, 0, 3, 2, 11, 10, 13, 5, 6, 5, 4, 5, 14, 0, 4, 2, 0, 11, 4, 5, 10, 3, 2, 7, 1, 13, 12, 13, 11, 13, 12, 8, 8, 0, 3, 3, 13, 4, 3, 4, 14, 9, 3, 8, 8, 9, 3, 0, 13, 6, 14, 0, 0, 5, 14, 11, 13, 7, 1, 12, 12, 7, 13, 4, 8, 14, 7, 13, 7, 6, 0, 13, 6, 9, 11, 8, 11, 12, 11, 1, 2, 3, 5, 0, 3, 4, 7, 0, 5, 12, 10, 11, 3, 3, 3, 5, 0, 2, 1, 13, 12, 12, 8, 4, 13, 3, 5, 13, 3, 0, 3, 6, 8, 6, 10, 6, 1, 13, 8, 4, 4, 9, 13, 11, 8, 6, 8, 0, 1, 12, 7, 2, 14, 6, 0, 13, 3, 4, 9, 4, 7, 14, 4, 4, 2, 12, 11, 8, 12, 8, 6, 0, 5, 14, 10, 11, 6, 2, 7, 13, 9, 5, 10, 2, 1, 0, 3, 1, 4, 4, 13, 10, 13, 14, 3, 0, 4, 7, 8, 6, 13, 5, 12, 12, 10, 6, 13, 1, 5, 12, 5, 6, 11, 7, 5, 12, 1, 13, 13, 13, 2, 9, 13, 8, 13, 1, 2, 12, 0, 6, 14, 14, 1, 4, 2, 6, 3, 13, 7, 2, 8, 9, 0, 0, 4, 12, 3, 9, 0, 13, 5, 10, 14, 2, 8, 7, 4, 9, 11, 12, 0, 12, 6, 2, 0, 5, 8, 8, 2, 1, 2, 2, 13, 9, 11, 1, 14, 4, 12, 10, 11, 10, 2, 6, 9, 8, 1, 14, 6, 5, 13, 5, 14, 11, 14, 4, 4, 7, 4, 10, 5, 5, 6, 10, 12, 13, 3, 8, 8, 6, 11, 9, 0, 7, 0, 0, 8, 7, 3, 1, 0, 3, 4, 0, 11, 6, 13, 12, 10, 5, 0, 13, 3, 14, 2, 14, 10, 3, 1, 8, 14, 5, 0, 5, 2, 12, 10, 1, 13, 12, 1, 8, 14, 10, 5, 6, 13, 6, 4, 7, 4, 0, 10, 6, 3, 3, 6, 12, 3, 13, 6, 12, 4, 6, 4, 6, 5, 12, 2, 7, 2, 3, 13, 5, 11, 13, 11, 4, 8, 10, 5, 4, 13, 14, 1, 11, 5, 1, 3, 6, 8, 14, 9, 6, 4, 11, 10, 2, 13, 12, 2, 14, 2, 11, 6, 1, 14, 14, 11, 10, 6, 8, 8, 11, 10, 13, 7, 9, 7, 0, 8, 1, 1, 9, 10, 6, 13, 12, 4, 14, 7, 6, 9, 10, 13, 8, 0, 6, 0, 8, 12, 12, 2, 12, 13, 11, 7, 12, 0, 14, 13, 0, 1, 0, 6, 8, 9, 5, 5, 6, 4, 9, 12, 5, 10, 0, 9, 4, 14, 1, 2, 11, 9, 13, 14, 2, 0, 7, 10, 13, 12, 7, 0, 9, 14, 5, 1, 9, 10, 12, 7, 11, 1, 12, 14, 2, 4, 0, 4, 11, 0, 11, 11, 0, 14, 2, 5, 6, 0, 13, 1, 7, 8, 2, 13, 9, 7, 0, 12, 1, 1, 2, 14, 1, 3, 7, 5, 0, 10, 14, 0, 10, 11, 2, 9, 12, 0, 8, 8, 4, 6, 3, 7, 2, 14, 13, 13, 4, 1, 2, 2, 3, 12, 0, 11, 14, 14, 4, 6, 0, 8, 13, 7, 13, 6, 0, 3, 14, 5, 2, 2, 3, 2, 8, 12, 10, 3, 11, 7, 13, 6, 3, 3, 14, 8, 1, 14, 14, 12, 3, 1, 4, 9, 10, 2, 1, 4, 1, 8, 11, 10, 5, 0, 4, 9, 14, 1, 13, 2, 5, 13, 6, 5, 2, 11, 2, 2, 10, 8, 10, 14, 3, 10, 13, 6, 2, 9, 5, 0, 11, 5, 12, 7, 12, 5, 9, 2, 0, 12, 13, 3, 12, 2, 11, 12, 0, 10, 11, 10, 9, 10, 11, 7, 13, 9, 5, 14, 14, 13, 12, 1, 4, 3, 6, 13, 6, 14, 1, 2, 9, 2, 2, 5, 14, 10, 12, 2, 2, 8, 14, 1, 0, 14, 4, 1, 2, 8, 3, 9, 3, 13, 13, 13, 13, 4, 7, 2, 12, 5, 11, 6, 4, 9, 13, 0, 11, 11, 12, 10, 3, 1, 0, 3, 6, 3, 11, 6, 0, 1, 8, 3, 12, 10, 11, 8, 1, 9, 14, 8, 1, 9, 0, 14, 3, 4, 6, 5, 2, 13, 7, 3, 12, 1, 8, 13, 13, 2, 12, 11, 10, 3, 4, 13, 1, 3, 14, 6, 4, 4, 11, 5, 2, 7, 7, 6, 5, 5, 6, 9, 0, 10, 8, 5, 2, 5, 13, 9, 1, 14, 7, 9, 1, 8, 12, 0, 10, 8, 12, 10, 0, 12, 10, 6, 6, 0, 11, 1, 10, 1, 12, 11, 10, 3, 14, 0, 5, 11, 13, 3, 1, 8, 1, 8, 1, 1, 5, 2, 10, 3, 12, 1, 10, 12, 12, 9, 0, 11, 14, 1, 0, 4, 9, 10, 1, 7, 3, 2, 2, 8, 6, 5, 3, 9, 14, 11, 4, 12, 12, 3, 8, 5, 6, 3, 7, 14, 0, 13, 12, 11, 10, 2, 0, 4, 12, 8, 11, 6, 4, 13, 3, 14, 2, 5, 9, 7, 0, 14, 0, 1, 9, 11, 14, 4, 14, 9, 12, 6, 2, 4, 7, 12, 5, 12, 3, 7, 12, 7, 3, 9, 13, 6, 10, 6, 6, 3, 9, 10, 9, 13, 6, 11, 13, 5, 6, 12, 11, 8, 2, 5, 14, 3, 9, 14, 2, 11, 10, 0, 9, 6, 1, 6, 1, 4, 1, 12, 2, 3, 14, 1, 9, 7, 14, 7, 2, 5, 6, 1, 14, 0, 14, 9, 6, 3, 7, 4, 2, 2, 13, 8, 8, 10, 8, 1, 0, 14, 0, 3, 3, 11, 2, 13, 11, 11, 12, 6, 3, 1, 13, 14, 8, 5, 11, 0, 0, 9, 12, 11, 4, 12, 3, 2, 10, 13, 8, 10, 5, 4, 10, 7, 1, 2, 8, 11, 0, 1, 2, 6, 4, 8, 11, 2, 0, 4, 9, 14, 13, 14, 11, 2, 11, 2, 14, 2, 14, 12, 6, 7, 2, 11, 12, 9, 9, 5, 5, 9, 4, 0, 3, 12, 10, 12, 8, 11, 13, 7, 0, 2, 9, 4, 7, 9, 11, 3, 9, 13, 13, 13, 12, 1, 4, 8, 8, 13, 9, 2, 0, 9, 2, 8, 14, 5, 6, 10, 4, 4, 1, 4, 9, 0, 9, 4, 14, 0, 4, 7, 0, 9, 8, 12, 3, 0, 8, 1, 12, 8, 14, 4, 9, 14, 2, 5, 13, 13, 2, 12, 9, 7, 1, 8, 2, 0, 13, 14, 6, 9, 4, 11, 1, 10, 4, 6, 13, 10, 13, 6, 11, 2, 11, 8, 0, 1, 3, 1, 2, 3, 13, 7, 6, 1, 2, 0, 9, 13, 4, 7, 13, 3, 6, 0, 14, 4, 13, 4, 5, 2, 0, 2, 13, 11, 10, 8, 5, 8, 10, 10, 14, 10, 8, 9, 14, 10, 6, 13, 13, 9, 11, 5, 11, 7, 1, 8, 2, 8, 6, 10, 4, 5, 2, 8, 9, 8, 0, 2, 14, 13, 9, 0, 8, 3, 13, 2, 5, 12, 13, 1, 3, 10, 9, 11, 9, 14, 12, 1, 12, 7, 14, 7, 1, 3, 11, 12, 9, 12, 9, 1, 2, 9, 1, 11, 9, 9, 7, 14, 4, 4, 4, 13, 14, 1, 8, 7, 6, 9, 12, 1, 9, 2, 10, 0, 10, 12, 7, 5, 12, 4, 11, 4, 12, 11, 0, 12, 4, 6, 12, 6, 4, 5, 10, 12, 3, 5, 10, 5, 5, 1, 4, 12, 6, 14, 13, 3, 5, 10, 4, 12, 14, 12, 2, 14, 9, 2, 7, 6, 5, 13, 5, 12, 3, 11, 10, 6, 11, 1, 7, 14, 6, 3, 7, 14, 0, 5, 5, 3, 11, 14, 11, 3, 0, 0, 6, 1, 12, 1, 7, 7, 11, 12, 14, 11, 14, 3, 1, 1, 7, 2, 11, 0, 2, 9, 7, 2, 10, 7, 11, 9, 7, 9, 0, 9, 4, 11, 7, 6, 12, 0, 0, 2, 5, 10, 8, 4, 3, 9, 13, 10, 1, 2, 8, 3, 5, 0, 3, 13, 6, 0, 7, 7, 10, 6, 2, 0, 5, 8, 1, 14, 6, 2, 1, 14, 9, 12, 12, 3, 3, 9, 4, 14, 10, 12, 4, 8, 12, 2, 10, 11, 4, 13, 11, 12, 5, 3, 8, 12, 8, 1, 1, 0, 13, 13, 13, 6, 12, 4, 8, 6, 3, 10, 7, 4, 12, 11, 13, 0, 13, 5, 4, 2, 14, 12, 3, 6, 4, 2, 14, 12, 8, 7, 2, 10, 5, 9, 1, 13, 13, 11, 2, 2, 11, 11, 9, 10, 14, 14, 2, 0, 0, 14, 13, 5, 4, 6, 13, 7, 5, 9, 12, 6, 1, 9, 0, 6, 3, 12, 4, 10, 0, 12, 4, 14, 6, 9, 12, 1, 4, 8, 13, 3, 14, 0, 0, 14, 12, 4, 7, 5, 3, 8, 10, 4, 1, 8, 9, 0, 13, 14, 1, 1, 5, 4, 5, 10, 1, 1, 14, 8, 2, 5, 14, 0, 5, 0, 5, 6, 6, 7, 12, 3, 13, 11, 0, 13, 1, 8, 8, 12, 10, 6, 1, 11, 14, 12, 5, 1, 4, 10, 0, 4, 9, 1, 9, 8, 10, 7, 7, 8, 9, 5, 4, 14, 13, 8, 7, 7, 6, 13, 2, 11, 9, 9, 11, 9, 7, 13, 1, 2, 5, 3, 5, 12, 8, 5, 3, 7, 0, 2, 1, 9, 13, 1, 5, 8, 3, 8, 4, 1, 3, 9, 1, 12, 7, 9, 3, 14, 10, 7, 10, 9, 7, 11, 9, 7, 5, 14, 1, 8, 1, 0, 6, 7, 6, 13, 6, 13, 6, 2, 0, 9, 8, 7, 4, 9, 4, 2, 1, 0, 10, 3, 3, 2, 2, 4, 7, 5, 13, 3, 13, 7, 10, 7, 7, 6, 6, 4, 6, 6, 8, 4, 6, 1, 12, 12, 2, 7, 2, 3, 8, 7, 3, 10, 5, 6, 14, 5, 7, 12, 4, 8, 1, 0, 7, 2, 6, 2, 5, 13, 5, 11, 5, 5, 1, 9, 0, 2, 3, 11, 9, 2, 0, 14, 4, 13, 14, 10, 13, 6, 4, 14, 5, 2, 4, 12, 5, 6, 2, 4, 11, 10, 6, 9, 10, 12, 13, 4, 6, 14, 0, 6, 8, 14, 13, 2, 11, 3, 3, 14, 2, 5, 7, 12, 5, 13, 12, 2, 8, 1, 12, 11, 4, 14, 6, 1, 6, 6, 13, 3, 13, 5, 5, 6, 12, 5, 5, 7, 3, 12, 2, 14, 1, 9, 4, 14, 9, 3, 10, 5, 3, 3, 13, 2, 3, 9, 10, 12, 13, 1, 6, 2, 4, 3, 5, 6, 11, 7, 13, 10, 0, 8, 3, 0, 2, 1, 9, 10, 0, 2, 6, 6, 0, 3, 3, 4, 4, 4, 10, 1, 12, 9, 0, 5, 5, 6, 12, 9, 6, 12, 9, 0, 14, 7, 1, 3, 4, 13, 5, 10, 12, 8, 12, 0, 1, 8, 14, 9, 7, 12, 2, 0, 2, 9, 3, 3, 13, 9, 11, 14, 9, 13, 14, 4, 14, 3, 12, 9, 5, 2, 14, 1, 9, 12, 8, 13, 12, 2, 2, 0, 9, 8, 0, 2, 11, 1, 10, 12, 3, 0, 14, 5, 13, 4, 13, 3, 0, 14, 4, 12, 1, 3, 7, 1, 2, 14, 12, 0, 8, 7, 5, 14, 1, 1, 0, 5, 12, 2, 4, 13, 10, 3, 6, 5, 8, 3, 9, 10, 0, 12, 6, 2, 5, 1, 10, 12, 5, 11, 7, 13, 9, 12, 6, 7, 14, 7, 0, 11, 6, 12, 2, 11, 10, 10, 3, 14, 0, 7, 5, 14, 9, 0, 12, 2, 4, 6, 3, 9, 7, 3, 4, 11, 8, 0, 11, 14, 9, 13, 4, 6, 13, 8, 8, 14, 0, 7, 10, 6, 3, 14, 12, 3, 1, 5, 12, 4, 6, 8, 6, 3, 4, 5, 4, 0, 2, 10, 13, 11, 9, 12, 8, 11, 8, 0, 14, 6, 2, 0, 0, 7, 9, 8, 3, 1, 13, 9, 13, 14, 5, 13, 12, 14, 2, 10, 13, 6, 8, 1, 4, 11, 2, 9, 14, 4, 0, 10, 14, 0, 5, 9, 11, 12, 3, 9, 4, 3, 6, 7, 7, 3, 0, 11, 8, 10, 12, 6, 10, 5, 2, 8, 1, 11, 7, 10, 3, 12, 11, 2, 7, 0, 13, 5, 0, 10, 9, 0, 4, 9, 12, 1, 13, 10, 8, 3, 8, 1, 1, 3, 7, 10, 7, 6, 14, 13, 9, 13, 14, 11, 10, 12, 4, 11, 3, 1, 12, 5, 7, 0, 3, 3, 10, 11, 6, 1, 9, 8, 12, 1, 11, 6, 10, 0, 3, 13, 6, 3, 1, 2, 7, 14, 3, 5, 10, 5, 13, 5, 14, 4, 11, 2, 8, 2, 9, 12, 3, 7, 5, 10, 0, 9, 9, 10, 1, 11, 9, 9, 3, 5, 0, 3, 9, 8, 0, 10, 8, 10, 2, 10, 3, 12, 2, 12, 9, 6, 6, 4, 14, 2, 8, 8, 1, 9, 7, 6, 13, 0, 10, 1, 12, 10, 2, 14, 5, 4, 11, 3, 9, 6, 5, 9, 2, 1, 7, 10, 7, 12, 6, 2, 9, 6, 4, 3, 9, 11, 4, 8, 2, 12, 8, 10, 12, 6, 12, 13, 5, 10, 8, 9, 13, 14, 9, 9, 12, 8, 2, 13, 4, 6, 11, 7, 7, 12, 11, 5, 14, 12, 13, 10, 10, 2, 11, 0, 0, 6, 10, 1, 5, 1, 12, 5, 3, 3, 1, 4, 4, 4, 11, 1, 12, 6, 12, 11, 9, 13, 4, 10, 10, 9, 9, 14, 13, 6, 14, 8, 13, 6, 7, 1]\n","[8, 13, 9, 9, 0, 3, 5, 9, 6, 13, 14, 3, 6, 11, 11, 0, 12, 1, 6, 12, 9, 0, 12, 12, 7, 4, 8, 0, 4, 1, 1, 14, 0, 2, 4, 7, 3, 3, 8, 12, 10, 8, 7, 4, 1, 7, 7, 0, 11, 3, 1, 3, 13, 10, 0, 8, 3, 8, 3, 13, 12, 8, 2, 9, 8, 8, 5, 3, 12, 3, 0, 12, 13, 1, 0, 13, 6, 7, 2, 2, 1, 0, 4, 8, 11, 5, 10, 13, 2, 14, 4, 5, 7, 6, 6, 3, 4, 14, 1, 12, 10, 0, 0, 12, 12, 13, 1, 0, 0, 8, 5, 8, 3, 3, 14, 0, 3, 12, 2, 9, 2, 4, 11, 2, 13, 8, 8, 5, 6, 3, 6, 7, 13, 11, 3, 13, 7, 0, 13, 2, 4, 9, 11, 14, 13, 10, 14, 8, 6, 13, 12, 5, 7, 13, 8, 4, 11, 6, 6, 9, 6, 11, 8, 14, 0, 9, 8, 0, 1, 3, 9, 12, 9, 1, 4, 10, 3, 3, 3, 0, 3, 9, 4, 8, 6, 10, 1, 9, 0, 3, 0, 8, 8, 10, 2, 10, 0, 1, 6, 12, 2, 8, 11, 5, 8, 9, 13, 0, 0, 3, 2, 3, 10, 13, 5, 6, 5, 6, 5, 4, 0, 5, 2, 0, 9, 4, 5, 10, 11, 6, 7, 13, 13, 13, 13, 3, 13, 2, 8, 8, 2, 3, 3, 13, 4, 8, 1, 14, 9, 9, 0, 8, 9, 11, 0, 13, 6, 14, 0, 0, 5, 3, 5, 13, 7, 1, 1, 12, 7, 13, 8, 0, 8, 7, 13, 14, 6, 1, 13, 2, 9, 3, 8, 11, 10, 5, 1, 2, 6, 6, 0, 7, 4, 7, 0, 8, 4, 10, 12, 2, 3, 7, 3, 0, 2, 3, 13, 12, 8, 8, 4, 13, 3, 5, 13, 3, 2, 3, 2, 1, 6, 10, 6, 1, 13, 12, 4, 8, 9, 13, 14, 8, 6, 8, 9, 0, 12, 12, 0, 8, 6, 0, 13, 3, 4, 9, 12, 2, 5, 4, 1, 2, 8, 3, 8, 4, 8, 2, 0, 5, 12, 10, 5, 6, 6, 0, 13, 9, 0, 10, 2, 1, 0, 3, 0, 4, 14, 13, 10, 13, 12, 3, 7, 2, 1, 8, 12, 13, 5, 6, 1, 10, 3, 12, 3, 5, 8, 5, 9, 1, 12, 5, 0, 1, 13, 13, 13, 7, 9, 13, 8, 13, 0, 2, 12, 0, 14, 4, 5, 8, 4, 0, 3, 7, 1, 0, 2, 1, 9, 13, 0, 4, 12, 11, 9, 0, 13, 5, 10, 7, 2, 8, 10, 14, 8, 11, 0, 0, 0, 6, 2, 0, 3, 8, 1, 2, 13, 6, 2, 13, 9, 11, 12, 8, 5, 12, 10, 5, 10, 7, 6, 9, 8, 13, 14, 0, 5, 13, 11, 5, 4, 14, 4, 4, 7, 4, 10, 11, 11, 2, 10, 8, 13, 3, 8, 8, 6, 10, 9, 0, 7, 2, 0, 8, 10, 14, 8, 0, 3, 8, 0, 11, 14, 13, 8, 10, 5, 0, 13, 3, 14, 12, 10, 10, 0, 1, 8, 12, 5, 4, 5, 2, 12, 10, 1, 13, 0, 8, 8, 0, 10, 11, 6, 13, 6, 4, 7, 4, 0, 10, 12, 3, 3, 6, 3, 0, 13, 6, 13, 4, 6, 4, 6, 5, 12, 2, 2, 0, 3, 1, 11, 13, 13, 5, 4, 8, 10, 5, 4, 13, 14, 7, 11, 5, 1, 0, 6, 9, 14, 9, 6, 8, 3, 10, 2, 13, 4, 14, 4, 2, 7, 6, 1, 4, 14, 3, 10, 3, 3, 8, 11, 10, 13, 2, 9, 7, 0, 8, 1, 8, 9, 10, 6, 13, 3, 4, 8, 13, 6, 9, 10, 13, 8, 0, 6, 3, 8, 12, 7, 7, 1, 13, 2, 12, 6, 3, 0, 13, 0, 1, 0, 6, 12, 9, 5, 5, 6, 4, 9, 1, 5, 10, 0, 9, 4, 14, 1, 6, 4, 9, 13, 6, 2, 0, 12, 10, 13, 8, 0, 7, 9, 10, 5, 3, 9, 10, 7, 14, 11, 9, 8, 14, 2, 6, 0, 4, 11, 0, 11, 5, 2, 3, 2, 5, 6, 0, 13, 4, 7, 7, 2, 13, 9, 1, 0, 1, 1, 13, 6, 11, 1, 8, 7, 14, 0, 10, 14, 0, 10, 5, 2, 9, 1, 0, 8, 1, 4, 6, 7, 7, 2, 6, 13, 13, 4, 11, 2, 6, 7, 0, 0, 0, 14, 12, 4, 6, 3, 8, 13, 7, 13, 6, 7, 6, 12, 5, 2, 2, 1, 2, 1, 14, 1, 13, 3, 1, 13, 6, 3, 3, 1, 8, 7, 3, 14, 14, 3, 1, 4, 9, 14, 2, 1, 4, 1, 8, 5, 10, 11, 2, 4, 9, 12, 10, 13, 12, 5, 13, 6, 13, 2, 5, 2, 2, 10, 8, 10, 12, 0, 10, 13, 6, 2, 8, 5, 3, 4, 5, 0, 7, 11, 14, 9, 6, 3, 3, 13, 12, 12, 4, 5, 8, 0, 10, 3, 10, 9, 10, 5, 6, 13, 9, 5, 11, 11, 13, 13, 4, 12, 11, 6, 13, 6, 6, 1, 2, 9, 12, 2, 11, 1, 10, 12, 2, 13, 8, 14, 13, 0, 8, 4, 7, 2, 6, 3, 9, 9, 13, 13, 13, 13, 4, 7, 6, 8, 5, 11, 0, 13, 9, 13, 7, 11, 12, 12, 10, 3, 1, 3, 3, 6, 6, 11, 8, 2, 6, 8, 6, 8, 10, 3, 8, 8, 9, 6, 8, 1, 9, 0, 11, 14, 4, 14, 5, 2, 13, 7, 3, 1, 1, 8, 13, 13, 2, 8, 11, 10, 0, 4, 13, 6, 14, 14, 6, 4, 4, 0, 12, 2, 0, 12, 6, 5, 5, 6, 9, 7, 10, 7, 10, 2, 5, 13, 9, 1, 3, 6, 9, 1, 8, 13, 0, 10, 8, 8, 10, 0, 13, 10, 6, 4, 2, 4, 1, 10, 2, 12, 11, 10, 0, 5, 0, 5, 11, 13, 3, 13, 8, 13, 8, 3, 1, 5, 2, 10, 3, 12, 0, 14, 1, 12, 9, 0, 5, 4, 1, 0, 4, 9, 10, 1, 7, 5, 2, 2, 8, 6, 5, 1, 9, 8, 5, 4, 8, 8, 11, 8, 5, 6, 3, 3, 6, 0, 13, 14, 11, 10, 6, 0, 4, 7, 8, 3, 6, 4, 13, 3, 8, 2, 5, 9, 7, 0, 11, 0, 13, 9, 3, 14, 4, 14, 9, 14, 6, 2, 4, 7, 13, 5, 12, 3, 1, 12, 0, 5, 9, 13, 8, 10, 2, 6, 13, 9, 10, 9, 13, 6, 10, 13, 5, 7, 14, 5, 8, 2, 3, 0, 7, 9, 12, 10, 11, 10, 7, 14, 2, 1, 7, 0, 4, 11, 8, 3, 10, 14, 8, 9, 7, 3, 13, 2, 5, 6, 13, 3, 0, 14, 9, 6, 5, 7, 4, 2, 2, 13, 8, 8, 10, 11, 11, 1, 11, 7, 3, 1, 4, 2, 13, 11, 11, 13, 6, 3, 1, 13, 6, 8, 5, 3, 0, 2, 9, 8, 3, 4, 12, 3, 2, 10, 13, 8, 10, 5, 4, 10, 7, 13, 7, 12, 12, 0, 12, 2, 11, 4, 8, 11, 2, 0, 10, 9, 5, 13, 14, 5, 6, 4, 6, 12, 2, 12, 9, 6, 1, 14, 8, 1, 9, 9, 5, 11, 9, 4, 0, 3, 2, 10, 1, 8, 11, 13, 0, 5, 2, 9, 2, 1, 9, 2, 0, 9, 13, 13, 13, 12, 1, 4, 8, 6, 13, 9, 6, 8, 9, 3, 8, 12, 5, 6, 10, 4, 4, 12, 4, 9, 0, 9, 4, 1, 0, 4, 7, 0, 9, 8, 12, 14, 1, 14, 11, 7, 8, 14, 4, 9, 1, 0, 5, 13, 13, 6, 7, 9, 1, 8, 8, 2, 0, 13, 14, 6, 9, 4, 12, 0, 10, 13, 2, 13, 10, 13, 11, 0, 2, 13, 8, 0, 8, 3, 13, 2, 3, 13, 2, 6, 1, 2, 0, 10, 13, 4, 2, 13, 3, 3, 2, 6, 4, 13, 4, 5, 2, 0, 2, 13, 13, 10, 8, 5, 8, 10, 10, 1, 10, 3, 9, 14, 10, 6, 13, 13, 9, 3, 14, 3, 7, 1, 12, 3, 8, 2, 10, 4, 3, 2, 8, 9, 8, 0, 2, 14, 13, 9, 3, 8, 3, 13, 9, 5, 1, 1, 8, 14, 10, 9, 5, 9, 14, 14, 1, 12, 0, 14, 11, 1, 14, 11, 12, 9, 4, 9, 1, 7, 9, 1, 11, 9, 9, 9, 14, 4, 3, 4, 13, 14, 1, 8, 6, 6, 9, 7, 1, 9, 6, 10, 0, 10, 12, 13, 5, 13, 4, 11, 7, 13, 14, 0, 6, 11, 3, 8, 6, 4, 5, 10, 1, 3, 11, 10, 14, 5, 12, 4, 8, 6, 3, 13, 10, 5, 10, 3, 13, 4, 1, 2, 12, 9, 6, 7, 6, 5, 13, 5, 11, 3, 13, 10, 6, 0, 13, 7, 14, 2, 3, 7, 1, 6, 5, 5, 11, 11, 4, 5, 1, 2, 0, 6, 1, 12, 4, 13, 0, 5, 13, 14, 11, 8, 3, 1, 1, 8, 12, 14, 0, 11, 9, 1, 0, 10, 13, 0, 9, 3, 9, 3, 9, 7, 5, 7, 2, 7, 7, 0, 2, 5, 10, 14, 4, 3, 9, 13, 5, 1, 2, 0, 3, 5, 0, 3, 13, 6, 3, 7, 0, 10, 6, 2, 0, 11, 3, 8, 6, 3, 9, 1, 12, 9, 1, 6, 0, 1, 9, 4, 13, 10, 7, 4, 8, 12, 9, 10, 3, 4, 13, 7, 12, 5, 3, 8, 4, 8, 1, 1, 0, 13, 13, 1, 14, 13, 13, 8, 2, 3, 10, 7, 1, 1, 3, 13, 0, 13, 5, 4, 11, 6, 6, 2, 3, 4, 2, 14, 3, 8, 1, 2, 10, 5, 9, 1, 13, 13, 4, 2, 6, 5, 5, 9, 10, 14, 14, 4, 7, 0, 11, 13, 5, 7, 1, 13, 7, 5, 9, 12, 4, 1, 9, 0, 6, 3, 12, 4, 10, 2, 1, 8, 5, 3, 9, 1, 8, 2, 8, 13, 0, 14, 0, 0, 4, 1, 4, 0, 14, 11, 8, 10, 4, 1, 8, 9, 0, 13, 14, 1, 1, 5, 12, 5, 10, 1, 1, 12, 8, 2, 11, 4, 0, 3, 0, 5, 6, 6, 8, 8, 3, 8, 3, 0, 13, 9, 8, 3, 1, 10, 14, 13, 11, 14, 8, 5, 12, 4, 10, 8, 12, 9, 1, 9, 8, 10, 10, 12, 8, 9, 3, 4, 1, 13, 8, 3, 7, 6, 13, 2, 11, 9, 9, 11, 9, 7, 13, 8, 9, 5, 3, 5, 0, 8, 5, 14, 11, 1, 2, 1, 9, 13, 4, 5, 8, 3, 8, 4, 13, 3, 9, 8, 4, 13, 2, 14, 3, 10, 0, 10, 9, 7, 1, 9, 7, 11, 14, 8, 8, 1, 6, 11, 7, 6, 1, 6, 13, 6, 2, 0, 9, 8, 2, 4, 9, 4, 2, 1, 3, 10, 14, 3, 0, 2, 4, 12, 11, 13, 13, 13, 1, 10, 0, 12, 6, 6, 4, 6, 6, 12, 4, 6, 8, 12, 12, 2, 7, 6, 3, 8, 7, 2, 10, 5, 6, 14, 14, 7, 8, 8, 8, 1, 0, 7, 2, 6, 2, 8, 13, 5, 1, 10, 5, 0, 9, 0, 2, 11, 3, 9, 2, 7, 14, 2, 13, 14, 11, 13, 6, 4, 14, 5, 6, 4, 2, 5, 6, 2, 11, 5, 10, 6, 9, 10, 12, 13, 12, 14, 14, 0, 3, 1, 3, 13, 2, 11, 0, 7, 14, 2, 5, 3, 0, 5, 1, 10, 2, 6, 12, 12, 8, 4, 14, 6, 13, 6, 6, 9, 14, 13, 2, 5, 6, 8, 11, 5, 7, 3, 8, 6, 14, 13, 9, 14, 14, 9, 3, 10, 5, 0, 7, 13, 2, 0, 9, 10, 4, 13, 8, 6, 2, 4, 3, 14, 6, 11, 13, 13, 10, 0, 8, 11, 2, 2, 13, 9, 6, 0, 7, 3, 3, 14, 11, 3, 4, 4, 4, 10, 13, 6, 13, 14, 14, 5, 6, 1, 9, 6, 11, 9, 0, 2, 12, 1, 13, 8, 13, 5, 10, 12, 8, 8, 0, 1, 8, 6, 9, 7, 1, 3, 3, 6, 9, 0, 11, 13, 9, 11, 14, 9, 13, 8, 1, 1, 9, 12, 9, 5, 6, 6, 1, 9, 8, 8, 13, 11, 2, 2, 0, 9, 8, 8, 2, 5, 13, 10, 12, 3, 3, 0, 5, 13, 0, 13, 14, 0, 8, 1, 12, 13, 4, 1, 1, 2, 14, 12, 0, 8, 1, 5, 3, 8, 1, 0, 14, 1, 2, 4, 13, 10, 0, 11, 5, 8, 14, 9, 5, 2, 11, 2, 2, 5, 1, 10, 12, 3, 13, 7, 13, 9, 12, 6, 7, 14, 0, 3, 11, 5, 3, 2, 11, 10, 10, 0, 5, 0, 0, 5, 12, 9, 0, 1, 2, 4, 2, 14, 9, 12, 14, 4, 6, 8, 7, 3, 14, 9, 13, 8, 6, 13, 4, 8, 2, 3, 7, 10, 3, 7, 14, 10, 3, 1, 5, 8, 0, 6, 8, 3, 2, 8, 12, 4, 0, 7, 10, 13, 11, 9, 12, 8, 11, 8, 11, 14, 3, 4, 11, 3, 0, 9, 8, 10, 1, 13, 9, 13, 12, 5, 13, 12, 0, 2, 10, 13, 3, 8, 1, 4, 5, 2, 9, 9, 4, 0, 10, 14, 0, 14, 9, 4, 14, 3, 9, 1, 12, 6, 7, 3, 3, 0, 3, 8, 10, 12, 6, 13, 5, 2, 8, 13, 3, 7, 10, 3, 7, 1, 2, 7, 7, 13, 5, 3, 10, 9, 0, 4, 9, 1, 1, 13, 10, 8, 7, 8, 1, 1, 0, 0, 10, 0, 6, 12, 13, 9, 13, 6, 5, 10, 1, 4, 5, 7, 8, 12, 5, 0, 0, 3, 0, 10, 11, 14, 1, 9, 14, 4, 1, 3, 6, 10, 0, 0, 13, 6, 14, 0, 2, 0, 1, 7, 11, 10, 11, 13, 5, 14, 4, 13, 6, 8, 2, 14, 8, 3, 7, 5, 10, 0, 6, 9, 10, 1, 10, 9, 9, 3, 5, 6, 7, 9, 8, 0, 10, 8, 10, 2, 10, 6, 11, 8, 12, 9, 6, 2, 4, 1, 14, 8, 8, 1, 9, 8, 6, 13, 8, 10, 13, 12, 10, 7, 13, 11, 4, 11, 3, 9, 6, 5, 9, 2, 12, 1, 10, 14, 12, 2, 2, 9, 6, 4, 3, 9, 11, 4, 8, 2, 12, 8, 14, 4, 6, 1, 13, 5, 10, 8, 9, 13, 14, 13, 9, 1, 8, 2, 13, 1, 11, 3, 7, 7, 12, 3, 5, 14, 4, 13, 10, 10, 14, 3, 0, 0, 6, 10, 4, 11, 13, 9, 5, 6, 3, 1, 1, 4, 4, 5, 11, 4, 6, 11, 11, 9, 13, 4, 10, 10, 13, 14, 3, 13, 6, 14, 8, 13, 6, 1, 13]\n"]}]},{"cell_type":"code","source":["acc = accuracy_score([item for sublist in y_true for item in sublist], [item for sublist in y_pred for item in sublist])\n","print(\"accuracy : \",acc)"],"metadata":{"id":"Jfda3jGPy78k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["np.array(targets_list).shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9BOGKb7evBA6","executionInfo":{"status":"ok","timestamp":1642300874381,"user_tz":-420,"elapsed":319,"user":{"displayName":"Tuyen Duong Van","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtTacBQ6s-40IAkPpB9UiqHRK4GYzu8VaLeAEr9g=s64","userId":"13283457235207767479"}},"outputId":"34ac54ad-f2cb-4644-f0b5-7ec3bcaf017a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(250, 10)"]},"metadata":{},"execution_count":66}]},{"cell_type":"code","source":["y_pred.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gIchxb3gvDgs","executionInfo":{"status":"ok","timestamp":1642300638147,"user_tz":-420,"elapsed":323,"user":{"displayName":"Tuyen Duong Van","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjtTacBQ6s-40IAkPpB9UiqHRK4GYzu8VaLeAEr9g=s64","userId":"13283457235207767479"}},"outputId":"16528114-a239-4f95-d526-c9ddeb1616ab"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(250,)"]},"metadata":{},"execution_count":57}]},{"cell_type":"code","source":["result = tokenizer.encode_plus(\"Sinh viên trường Đại Học Bách Khoa Hà Nội Sinh viên trường Đại Học Bách Khoa Hà Nội\",return_tensors=\"pt\");"],"metadata":{"id":"GZeSEgflaJO2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"giFZEpiPgmuF","executionInfo":{"status":"ok","timestamp":1642320080005,"user_tz":-420,"elapsed":91360,"user":{"displayName":"Tuyển Dương","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgL_7fwmi-6wsXMnaiF7SDMv2ievunYgF-1pGos=s64","userId":"04424011376780897176"}},"outputId":"865d34ec-2939-4cd6-904f-15292d30d3f1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["result"],"metadata":{"id":"F5VWTHOxcA9B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["xlm(**result)"],"metadata":{"id":"CwYC8rEfmzXd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["o = xlm(torch.tensor([result['input_ids']]), attention_mask = torch.tensor([result['attention_mask']]), token_type_ids = torch.tensor(result['token_type_ids']))"],"metadata":{"id":"aysylDcGj_S8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["o"],"metadata":{"id":"V4iWvIGSl9k5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer.convert_ids_to_tokens(result['input_ids'])"],"metadata":{"id":"7SlEhoNGcBmQ"},"execution_count":null,"outputs":[]}]}